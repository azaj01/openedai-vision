[
  ["AIDC-AI/Ovis2-1B", "-A", "flash_attention_2"],
  ["AIDC-AI/Ovis2-2B", "-A", "flash_attention_2"],
  ["AIDC-AI/Ovis2-4B", "-A", "flash_attention_2"],
  ["AIDC-AI/Ovis2-8B", "-A", "flash_attention_2"],
  ["AIDC-AI/Ovis2-16B", "-A", "flash_attention_2"],
  ["AIDC-AI/Ovis2-34B", "-A", "flash_attention_2"],
  ["AIDC-AI/Ovis1.6-Llama3.2-3B", "-A", "flash_attention_2"],
  ["AIDC-AI/Ovis1.5-Llama3-8B", "-A", "flash_attention_2"],
  ["BAAI/Aquila-VL-2B-llava-qwen", "-A", "flash_attention_2", "--load-in-4bit"],
  ["BAAI/Aquila-VL-2B-llava-qwen", "-A", "flash_attention_2"],
  ["BAAI/Emu2-Chat", "--load-in-4bit"],
  ["CohereForAI/aya-vision-8b", "-A", "flash_attention_2"],
  ["CohereForAI/aya-vision-32b", "-A", "flash_attention_2"],
  ["HuggingFaceTB/SmolVLM-Instruct", "-A", "flash_attention_2", "--load-in-4bit"],
  ["HuggingFaceTB/SmolVLM-Instruct", "-A", "flash_attention_2"],
  ["HuggingFaceM4/Idefics3-8B-Llama3", "-A", "flash_attention_2", "--load-in-4bit"],
  ["HuggingFaceM4/Idefics3-8B-Llama3", "-A", "flash_attention_2"],
  ["OpenGVLab/InternVL-Chat-V1-5", "--device-map", "cuda:0", "--load-in-4bit"],
  ["OpenGVLab/InternVL-Chat-V1-5", "--device-map", "cuda:0", "--max-tiles", "40", "--load-in-4bit"],
  ["OpenGVLab/InternVL-Chat-V1-5", "--device-map", "cuda:0", "--max-tiles", "40"],
  ["OpenGVLab/InternVL-Chat-V1-5", "--device-map", "cuda:0"],
  ["OpenGVLab/InternVL2_5-1B", "--device-map", "cuda:0", "--max-tiles", "12", "--load-in-4bit"],
  ["OpenGVLab/InternVL2_5-1B", "--device-map", "cuda:0", "--max-tiles", "12"],
  ["OpenGVLab/InternVL2_5-2B", "--device-map", "cuda:0", "--max-tiles", "12", "--load-in-4bit"],
  ["OpenGVLab/InternVL2_5-2B", "--device-map", "cuda:0", "--max-tiles", "12"],
  ["OpenGVLab/InternVL2_5-4B", "--device-map", "cuda:0", "--max-tiles", "12", "--load-in-4bit"],
  ["OpenGVLab/InternVL2_5-4B", "--device-map", "cuda:0", "--max-tiles", "12"],
  ["OpenGVLab/InternVL2_5-8B", "--device-map", "cuda:0", "--max-tiles", "12", "--load-in-4bit"],
  ["OpenGVLab/InternVL2_5-8B", "--device-map", "cuda:0", "--max-tiles", "12"],
  ["OpenGVLab/InternVL2_5-26B", "--device-map", "cuda:0", "--max-tiles", "12", "--load-in-4bit"],
  ["OpenGVLab/InternVL2_5-26B", "--device-map", "cuda:0", "--max-tiles", "12"],
  ["OpenGVLab/InternVL2_5-38B", "--device-map", "cuda:0", "--max-tiles", "12", "--load-in-4bit"],
  ["OpenGVLab/InternVL2_5-38B", "--device-map", "cuda:0", "--max-tiles", "12"],
  ["OpenGVLab/InternVL2_5-78B", "--device-map", "cuda:0", "--max-tiles", "12", "--load-in-4bit"],
  ["OpenGVLab/InternVL2-1B", "--device-map", "cuda:0", "--load-in-4bit"],
  ["OpenGVLab/InternVL2-1B", "--device-map", "cuda:0"],
  ["OpenGVLab/InternVL2-2B", "--device-map", "cuda:0", "--load-in-4bit"],
  ["OpenGVLab/InternVL2-2B", "--device-map", "cuda:0"],
  ["OpenGVLab/InternVL2-8B", "--device-map", "cuda:0", "--load-in-4bit"],
  ["OpenGVLab/InternVL2-8B", "--device-map", "cuda:0"],
  ["OpenGVLab/InternVL2-26B", "--device-map", "cuda:0", "--load-in-4bit"],
  ["OpenGVLab/InternVL2-26B", "--device-map", "cuda:0"],
  ["OpenGVLab/InternVL2-40B", "--device-map", "cuda:0", "--load-in-4bit"],
  ["OpenGVLab/InternVL2-40B", "--device-map", "cuda:0"],
  ["OpenGVLab/InternVL2-Llama3-76B", "--device-map", "cuda:0", "--load-in-4bit"],
  ["OpenGVLab/Mini-InternVL-Chat-2B-V1-5", "--load-in-4bit"],
  ["OpenGVLab/Mini-InternVL-Chat-2B-V1-5", "--max-tiles", "40", "--load-in-4bit"],
  ["OpenGVLab/Mini-InternVL-Chat-2B-V1-5", "--max-tiles", "40"],
  ["OpenGVLab/Mini-InternVL-Chat-2B-V1-5"],
  ["Qwen/Qwen-VL-Chat", "--load-in-4bit"],
  ["Qwen/Qwen-VL-Chat"],
  ["Qwen/Qwen2-VL-2B-Instruct-AWQ", "-A", "flash_attention_2"],
  ["Qwen/Qwen2-VL-2B-Instruct", "-A", "flash_attention_2"],
  ["Qwen/Qwen2-VL-7B-Instruct-AWQ", "-A", "flash_attention_2"],
  ["Qwen/Qwen2-VL-7B-Instruct", "-A", "flash_attention_2"],
  ["Qwen/Qwen2-VL-72B-Instruct-AWQ", "-A", "flash_attention_2"],
  ["Qwen/Qwen2.5-VL-3B-Instruct-AWQ", "-F"],
  ["Qwen/Qwen2.5-VL-3B-Instruct", "-F"],
  ["Qwen/Qwen2.5-VL-7B-Instruct-AWQ", "-F"],
  ["Qwen/Qwen2.5-VL-7B-Instruct", "-F"],
  ["Qwen/Qwen2.5-VL-72B-Instruct", "-4F"],
  ["Qwen/Qwen2.5-VL-72B-Instruct-AWQ", "-F"],
  ["Qwen/QVQ-72B-Preview", "-A", "flash_attention_2", "--load-in-4bit"],
  ["kosbu/QVQ-72B-Preview-AWQ", "-A", "flash_attention_2"],
  ["Salesforce/xgen-mm-phi3-mini-instruct-dpo-r-v1.5"],
  ["Salesforce/xgen-mm-phi3-mini-instruct-interleave-r-v1.5"],
  ["Salesforce/xgen-mm-phi3-mini-instruct-singleimg-r-v1.5"],
  ["Salesforce/xgen-mm-phi3-mini-instruct-r-v1"],
  ["adept/fuyu-8b", "--device-map", "cuda:0", "--load-in-4bit"],
  ["adept/fuyu-8b", "--device-map", "cuda:0"],
  ["fancyfeast/joy-caption-alpha-two", "--load-in-4bit", "-A", "flash_attention_2"],
  ["fancyfeast/joy-caption-alpha-two", "-A", "flash_attention_2"],
  ["fancyfeast/joy-caption-pre-alpha", "-A", "flash_attention_2"],
  ["internlm/internlm-xcomposer2d5-7b", "-A", "flash_attention_2", "--device-map", "cuda:0", "--load-in-4bit"],
  ["internlm/internlm-xcomposer2d5-7b", "-A", "flash_attention_2", "--device-map", "cuda:0"],
  ["internlm/internlm-xcomposer2-4khd-7b", "-A", "flash_attention_2", "--device-map", "cuda:0"],
  ["llava-hf/llava-1.5-13b-hf", "-A", "flash_attention_2", "--device-map", "cuda:0", "--load-in-4bit"],
  ["llava-hf/llava-1.5-13b-hf", "-A", "flash_attention_2", "--device-map", "cuda:0"],
  ["llava-hf/llava-1.5-7b-hf", "-A", "flash_attention_2", "--device-map", "cuda:0", "--load-in-4bit"],
  ["llava-hf/llava-1.5-7b-hf", "-A", "flash_attention_2", "--device-map", "cuda:0"],
  ["llava-hf/llava-v1.6-34b-hf", "-A", "flash_attention_2", "--load-in-4bit"],
  ["llava-hf/llava-v1.6-34b-hf", "-A", "flash_attention_2"],
  ["llava-hf/llava-v1.6-vicuna-13b-hf", "-A", "flash_attention_2", "--load-in-4bit"],
  ["llava-hf/llava-v1.6-vicuna-13b-hf", "-A", "flash_attention_2"],
  ["llava-hf/llava-v1.6-vicuna-7b-hf", "-A", "flash_attention_2", "--load-in-4bit"],
  ["llava-hf/llava-v1.6-vicuna-7b-hf", "-A", "flash_attention_2"],
  ["lmms-lab/llava-onevision-qwen2-0.5b-ov", "-A", "flash_attention_2"],
  ["lmms-lab/llava-onevision-qwen2-7b-ov", "-A", "flash_attention_2"],
  ["meta-llama/Llama-3.2-11B-Vision-Instruct", "-A", "flash_attention_2", "--load-in-4bit"],
  ["meta-llama/Llama-3.2-11B-Vision-Instruct", "-A", "flash_attention_2"],
  ["meta-llama/Llama-3.2-90B-Vision-Instruct", "-A", "flash_attention_2", "--load-in-4bit"],
  ["microsoft/Florence-2-base-ft", "-A", "flash_attention_2", "--device-map", "cuda:0", "--load-in-4bit"],
  ["microsoft/Florence-2-base-ft", "-A", "flash_attention_2", "--device-map", "cuda:0"],
  ["mistralai/Pixtral-12B-2409"],
  ["mx262/MiniMonkey", "-A", "flash_attention_2", "--load-in-4bit"],
  ["mx262/MiniMonkey", "-A", "flash_attention_2"],
  ["openbmb/MiniCPM-V-2_6", "-A", "flash_attention_2", "--device-map", "cuda:0", "--load-in-4bit"],
  ["openbmb/MiniCPM-V-2_6", "-A", "flash_attention_2", "--device-map", "cuda:0"],
  ["openbmb/MiniCPM-Llama3-V-2_5", "-A", "flash_attention_2", "--device-map", "cuda:0", "--load-in-4bit"],
  ["openbmb/MiniCPM-Llama3-V-2_5", "-A", "flash_attention_2", "--device-map", "cuda:0"],
  ["qresearch/llama-3-vision-alpha-hf", "--device", "cuda:0", "--load-in-4bit"],
  ["qresearch/llama-3-vision-alpha-hf", "--device", "cuda:0"],
  ["vikhyatk/moondream2", "-A", "flash_attention_2", "--load-in-4bit"],
  ["vikhyatk/moondream2", "-A", "flash_attention_2"]
]
